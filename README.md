# Transformer-Readiing-Report🎉
# Transformer的论文阅读报告与代码简单实现🎉
## 🎄本项目包含对多篇Transformer论文及其衍生文章的论文精读报告及对代码的理解与复现

## 文档结构：
```
Transformer-Reading-Report/
|—— Attention is all you need/ |—— Attention is all you need report.md
                               |——

|—— Bert/ |—— Bert report.md
          |——

|—— VIT/  |—— VIT report.md
          |——

|—— swintransformer |—— swintransformer.report
                    |——

|—— README.md         
```
## 各个分项目重点内容：
### 包含链接与核心概念图，具体段落与补充知识请见论文阅读报告，实现复现后续补充
### （一）：Attention is all you need
#### 原论文链接：[Attention is all you need](https://arxiv.org/abs/1706.03762)
#### 借鉴视频讲解：[跟李沐学AI](https://www.bilibili.com/video/BV1pu411o7BE/?spm_id_from=333.999.0.0&vd_source=6e22f74cbbb0cdf9444235d6ad11aabf)
#### 论文阅读报告：[Attention is all you need report](https://github.com/Baiyouawa/Transformer-Reading-Report/blob/main/Attention%20is%20all%20you%20need/Attention%20is%20all%20you%20need%20report.md)

#### 核心图：
<table>
  <tr>
    <td><img src="images/Attention1.png" alt="Attention1" width="600"/></td>
    <td><img src="images/Attention2.png" alt="Attention2" width="700"/></td>
  </tr>
</table>


